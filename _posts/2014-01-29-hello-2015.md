---
layout:     post
title:      "线性转换(Linear Transformation)"
subtitle:   ""
date:       2018-11-19 15:55:00
author:     "pfzhang"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - Math
    - Computer Science
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>



# 线性代数(Linear Algebra)
本科的时候也学过线性代数，但是当时只是学了一遍，或者说只是为了考试学了一遍，当时从来没有问过学来干嘛，不过当我开始系统地学习PCA(Principal Component Analysis)
及SVD(Singular Value Decomposition)之后，我才发现，喔，原来线性代数还可以这么用, **有的时候，通过一些简单的转换，就可以以量级地减少某些应用的计算量**。这篇博客主要参考了一下这些资料：
- [Inner Product Spaces – A Primer](https://jeremykun.com/2011/07/25/inner-product-spaces-a-primer/)
- [Introduction to Linear Algebra](http://math.mit.edu/~gs/linearalgebra/)

在这篇博客中，我们重点要搞清楚一个概念，那就是线性变换

## 线性变换
一直以来，对向量 $$v$$ 做线性变换(linear transformation), 我都简单地认为是在 $$v$$ 左边乘以一个矩阵，$$Mv$$。
事实上线性变化其实是有一个非常严格的定义的，现在有一个变换，$$T$$，当输入一个向量$$v$$，输出一个值$$T(v)$$，
这个输出可以是一个向量，也可以是一个标量。只要变换$$T$$满足以下这些条件：
对于任意向量 $$v$$ 和$$w$$, 以及任意实数$$c$$，

$$T(v+w) = T(v) + T(w)$$

$$T(cv)=cT(v)$$

并且如果向量$$v=0$$，那么$$T(v)$$ 必须等于$$0$$（当然这个可以从第一个条件推导出来）。

现在我们需要问一个问题：是不是所有的从向量空间 $$V=R^n$$ 到向量空间 $$W=R^m$$ 的线性变换都是通过矩阵得来的，如$$w=Av$$? 当一个线性变换T被描述为旋转，投影等，其后是否总是存在着一个矩阵。答案是yes，所以我一开始的理解其实是正确的，至少在一般情况是这样。

现在假设某个线性转换$$T$$将一个$$n$$维的向量空间$$V$$转换到一个$$m$$维的向量空间$$W$$。其中空间$$V$$的基向量是$$v_1, v_2, v_3, ..., v_n$$, 空间$$W$$的基向量是$$w_1, w_2, w_3,..., w_m$$。 我们必然可以用一个矩阵$$A$$来来表示这个转换，那么如何求解这个矩阵？ 为了找到矩阵$$M$$的第一列，我们通过转换$$T$$ 将$$v_1$$转换为$$T(v_1)$$，因为$$T(v_1)$$ 存在于$$m$$维向量空间$$W$$中，所以可以用以下形式表示$$T(v_1)$$：

$$T(v_1)=a_{11}w_{1} + ... + a_{m1}w_{m}$$ 

$$a_{11}, a_{21}, ...,a_{m1}$$ 即矩阵$$A$$的第一列，同理，我们亦可以求出$$A$$的其他列。从$$A$$的求解过程中，我们也可以看出矩阵$$A$$取决于基向量$$\{v_i\}_{i=0}^n$$和$$\{w_{i}\}_{i=0}^{m}$$。

 








